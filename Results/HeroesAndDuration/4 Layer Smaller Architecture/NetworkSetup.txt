epochs = 2000
batchsize = 20000

model = Sequential()
model.add(Dense(1000, input_shape=(len(xtrain[0, :]),), activation='sigmoid'))
model.add(Dropout(0.1))
model.add(Dense(500, activation='sigmoid'))
model.add(Dropout(0.1))
model.add(Dense(100, activation='sigmoid'))
model.add(Dropout(0.1))
model.add(Dense(1, activation='sigmoid'))
a = adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)
#a = adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)
model.compile(optimizer=a, loss='binary_crossentropy', metrics=['accuracy'])
patience = 100

directory = 'C:/Users/baseb/PycharmProjects/Dota2Predictor/TensorBoard/HeroesAndDuration/4 Layer Smaller Architecture/'
if not os.path.exists(directory):
    os.makedirs(directory)

tbCallBack = TensorBoard(log_dir=directory, histogram_freq=0, write_graph=True, write_grads=False, write_images=False)
earlyStop = EarlyStopping(monitor='val_acc', patience=patience, min_delta=0, verbose=2, mode='auto')

class_weight = class_weight.compute_class_weight('balanced', np.unique(ytrain), ytrain)
class_weight_dict = dict(enumerate(class_weight))

acc = Get_Val_Acc()  # object used to find max acc of training
#callbacks_list = [tbCallBack, earlyStop, acc]
callbacks_list = [tbCallBack, acc]
model.fit(xtrain, ytrain_hot, epochs=epochs, callbacks=callbacks_list, class_weight=class_weight, validation_data=(xval, yval_hot),
          batch_size=batchsize, verbose=2, shuffle='true')
score = model.evaluate(xval, yval_hot, verbose=2)